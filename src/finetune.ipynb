{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "finetuning_torchvision_models_tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gGq95942DKk",
        "outputId": "09bf8e10-b586-4454-d31e-2e645428cf9a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd '/content/drive/My Drive/CSC420/CSC420_project-main/src'\n",
        "!ls"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/CSC420/CSC420_project-main/src\n",
            "arch\t\t\t\t\t      infer.py\t   test_out\n",
            "arch_st\t\t\t\t\t      __init__.py  test.py\n",
            "data\t\t\t\t\t      log.log\t   train_out\n",
            "finetuning_torchvision_models_tutorial.ipynb  main.py\t   train.py\n",
            "generate_lr.py\t\t\t\t      pretrained   util\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uZdpZtQ9FcY",
        "outputId": "e5ef1e9e-f9e7-4259-b37c-d3c30b4a43fc"
      },
      "source": [
        "# Remove problematic images (not the same size as all others)\n",
        "\n",
        "# %cd '/content/drive/My Drive/CSC420/CSC420_project-main/src/data/pokemon/hr'\n",
        "# !rm '077_f2.png' '555_f2.png' '263_f2.png' '110_f2.png' '745_f2.png' '422_f2.png' '264_f2.png' '745_f3.png'\n",
        "\n",
        "# %cd '/content/drive/My Drive/CSC420/CSC420_project-main/src/data/pokemon/lr'\n",
        "# !rm '077_f2.png' '555_f2.png' '263_f2.png' '110_f2.png' '745_f2.png' '422_f2.png' '264_f2.png' '745_f3.png'\n",
        "\n",
        "# %cd '/content/drive/My Drive/CSC420/CSC420_project-main/src'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/CSC420/CSC420_project-main/src/data/pokemon/hr\n",
            "/content/drive/My Drive/CSC420/CSC420_project-main/src/data/pokemon/lr\n",
            "/content/drive/My Drive/CSC420/CSC420_project-main/src\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ts4CyQazLY0K",
        "outputId": "bef30326-9f3f-488b-939a-f90549dc1a0a"
      },
      "source": [
        "# Split all data into train, validation, test sets\n",
        "\n",
        "# %cd '/content/drive/My Drive/CSC420/CSC420_project-main/src/data/pokemon/lr'\n",
        "# import os\n",
        "# import numpy as np\n",
        "# from shutil import copyfile\n",
        "\n",
        "# train_fp, val_fp, test_fp = [], [], []\n",
        "# for fp in os.listdir():\n",
        "#     if os.path.isfile(fp) and os.path.splitext(fp)[1] == \".png\":\n",
        "#         val = np.random.random()\n",
        "#         if val < 0.20:\n",
        "#             test_fp.append(fp)\n",
        "#         elif val < 0.40:\n",
        "#             val_fp.append(fp)\n",
        "#         else:\n",
        "#             train_fp.append(fp)\n",
        "\n",
        "# for folder in [\"train\", \"val\", \"test\"]:\n",
        "#     if folder not in os.listdir():\n",
        "#         os.mkdir(folder)\n",
        "\n",
        "# base_fp = '/content/drive/My Drive/CSC420/CSC420_project-main/src/data/pokemon/lr/'\n",
        "# for folder, fps in [(\"train/\", train_fp), (\"val/\", val_fp), (\"test/\", test_fp)]:\n",
        "#     for fp in fps:\n",
        "#         copyfile(base_fp + fp, base_fp + folder + fp)\n",
        "\n",
        "\n",
        "# %cd '/content/drive/My Drive/CSC420/CSC420_project-main/src/data/pokemon/hr'\n",
        "\n",
        "# for folder in [\"train\", \"val\", \"test\"]:\n",
        "#     if folder not in os.listdir():\n",
        "#         os.mkdir(folder)\n",
        "\n",
        "# base_fp = '/content/drive/My Drive/CSC420/CSC420_project-main/src/data/pokemon/hr/'\n",
        "# for folder, fps in [(\"train/\", train_fp), (\"val/\", val_fp), (\"test/\", test_fp)]:\n",
        "#     for fp in fps:\n",
        "#         copyfile(base_fp + fp, base_fp + folder + fp)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/CSC420/CSC420_project-main/src/data/pokemon/lr\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDE81ZWf1q5Q",
        "outputId": "c1043c91-9cdc-477f-d500-75c0a566f087"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "import argparse\n",
        "import logging\n",
        "logging.basicConfig(filename='./log.log')\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "from arch.srgan_model import Generator, Discriminator\n",
        "from arch.vgg19 import vgg19\n",
        "from data.dataset import *\n",
        "from arch.losses import TVLoss, perceptual_loss\n",
        "from util import arg_util"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch Version:  1.7.0+cu101\n",
            "Torchvision Version:  0.8.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEyjTTUV7f5q",
        "outputId": "e6a1c110-b7fa-422a-a086-5cc88b59d0c7"
      },
      "source": [
        "memcache=False\n",
        "batch_size=32\n",
        "num_workers=0\n",
        "\n",
        "scale=4\n",
        "patch_size=24\n",
        "model_res_count=16\n",
        "\n",
        "transfer_generator_path=arg_util.path_abs(\"pretrained/SRResNet.pt\")\n",
        "\n",
        "feat_layer='relu5_4'\n",
        "vgg_rescale_coeff=0.006\n",
        "adv_coeff=1e-3\n",
        "tv_loss_coeff=0.0\n",
        "\n",
        "t_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "t_device"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-g_v803wBgvf"
      },
      "source": [
        "import csv\n",
        "from skimage.color import rgb2ycbcr\n",
        "from skimage.metrics import peak_signal_noise_ratio\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Get PSNR for train, val, or test sets\n",
        "def test(generator_path=None, generator=None, mode=\"val\", write_img=False):\n",
        "    if mode == \"train\":\n",
        "        output_path = arg_util.path_abs(\"train_out/\")\n",
        "        psnr_result_filepath = arg_util.path_abs(\"train_out/psnr.txt\")\n",
        "        lr_path = arg_util.path_abs(\"data/pokemon/lr/train\")\n",
        "        gt_path = arg_util.path_abs(\"data/pokemon/hr/train\")\n",
        "    elif mode == \"test\":\n",
        "        output_path = arg_util.path_abs(\"test_out/\")\n",
        "        psnr_result_filepath = arg_util.path_abs(\"test_out/psnr.txt\")\n",
        "        lr_path = arg_util.path_abs(\"data/pokemon/lr/test\")\n",
        "        gt_path = arg_util.path_abs(\"data/pokemon/hr/test\")\n",
        "    else:\n",
        "        output_path = arg_util.path_abs(\"val_out/\")\n",
        "        psnr_result_filepath = arg_util.path_abs(\"val_out/psnr.txt\")\n",
        "        lr_path = arg_util.path_abs(\"data/pokemon/lr/val\")\n",
        "        gt_path = arg_util.path_abs(\"data/pokemon/hr/val\")\n",
        "    psnr_result_filepath.parent.mkdir(parents=True, exist_ok=True)\n",
        "    # print(lr_path, gt_path)\n",
        "    memcache = False\n",
        "    filename_prefix=\"\"\n",
        "\n",
        "    lr_gt_dataset = LowResGroundTruthDataset(lr_dir=lr_path, gt_dir=gt_path, memcache=memcache, transform=None)\n",
        "    loader = DataLoader(lr_gt_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "    if generator_path:\n",
        "        generator = Generator(img_feat=3, n_feats=64, kernel_size=3, num_block=model_res_count, scale=scale)\n",
        "        generator.load_state_dict(torch.load(generator_path, map_location=t_device))\n",
        "        generator = generator.to(t_device)\n",
        "    generator.eval()\n",
        "\n",
        "    # print(f\"Starting Testing.\")\n",
        "    logging.info(f\"Starting Testing.\")\n",
        "    with torch.no_grad():\n",
        "        psnr_data = []\n",
        "        psnr_vals = []\n",
        "        for batch_i, lr_gt_datum in enumerate(loader):\n",
        "            img_filenames, img_lrs = lr_gt_datum['img_filename'], lr_gt_datum['img_lr'].to(t_device)\n",
        "            img_hr_predictions, _ = generator(img_lrs)\n",
        "            img_gts = lr_gt_datum['img_gt'].to(t_device)\n",
        "            for i in range(len(img_filenames)):  # Independent of batch size.\n",
        "                img_filename = img_filenames[i]\n",
        "\n",
        "                img_gt = ((img_gts[i].cpu().numpy() + 1.) / 2.).transpose(1, 2, 0)\n",
        "                img_hr_prediction = ((np.clip(img_hr_predictions[i].cpu().numpy(), -1., 1.) + 1.) / 2.).transpose(1, 2, 0)\n",
        "\n",
        "                # Since no transforms are used, resize GT to ensure its the same as HR.\n",
        "                img_gt = img_gt[:img_hr_prediction.shape[0], :img_hr_prediction.shape[1], :]\n",
        "\n",
        "                # Calculate psnr from ycbcr comparison.\n",
        "                y_hr_prediction = rgb2ycbcr(img_hr_prediction)[scale:-scale, scale:-scale, :1]\n",
        "                y_gt = rgb2ycbcr(img_gt)[scale:-scale, scale:-scale, :1]\n",
        "                psnr = peak_signal_noise_ratio(y_gt / 255., y_hr_prediction / 255., data_range=1.)\n",
        "                psnr_data.append({'img_filepath': str(lr_gt_dataset.lr_dir / img_filename), 'psnr': psnr})\n",
        "                logging.info(f\"{img_filename}: psnr={psnr}\")\n",
        "                # print(f\"{img_filename}: psnr={psnr}\")\n",
        "                psnr_vals.append(psnr)\n",
        "                if write_img:\n",
        "                    result = Image.fromarray((img_hr_prediction * 255.).astype(np.uint8))\n",
        "                    result.save(output_path / f\"pred_{img_filename}\")\n",
        "                    logging.info(f\"Inference Output: {output_path / f'pred_{img_filename}'}\")\n",
        "        # print(f\"Average PSNR: {sum(psnr_vals)/len(psnr_vals)}\")\n",
        "\n",
        "        if psnr_result_filepath:\n",
        "            with open(psnr_result_filepath, 'w') as fp_psrn_results:\n",
        "                writer = csv.DictWriter(fp_psrn_results, fieldnames=['img_filepath', 'psnr'])\n",
        "                writer.writeheader()\n",
        "                writer.writerows(psnr_data)\n",
        "\n",
        "    generator.train()\n",
        "    return sum(psnr_vals)/len(psnr_vals)"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-Gy84gE1VR2",
        "outputId": "2d6dcc78-c526-4998-a345-4cd5ed0a2f03"
      },
      "source": [
        "test(transfer_generator_path, mode=\"train\")"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average PSNR: 20.159482897498478\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20.159482897498478"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ihS2t8cT7VM"
      },
      "source": [
        "# Load Training Data\n",
        "generator_path_out = arg_util.path_abs(\"train_out/SRGAN_g.pt\")\n",
        "generator_path_out.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "discriminator_path_out = arg_util.path_abs(\"train_out/SRGAN_d.pt\")\n",
        "discriminator_path_out.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "checkpoint_dir = arg_util.path_abs(\"train_out/\")\n",
        "checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "gt_path = arg_util.path_abs(\"data/pokemon/hr/train/\")\n",
        "lr_path = arg_util.path_abs(\"data/pokemon/lr/train/\")\n",
        "\n",
        "lr_gt_dataset = LowResGroundTruthDataset(\n",
        "    lr_dir=lr_path, gt_dir=gt_path, memcache=memcache,\n",
        "    transform=transforms.Compose([\n",
        "        Crop_LR_GT_PairTransform(scale, patch_size),\n",
        "        Random_LR_GT_AugmentationTransform()\n",
        "    ])\n",
        ")\n",
        "\n",
        "loader = DataLoader(lr_gt_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "generator = Generator(img_feat=3, n_feats=64, kernel_size=3, num_block=model_res_count, scale=scale)\n",
        "if transfer_generator_path:\n",
        "    generator.load_state_dict(torch.load(transfer_generator_path, map_location=t_device))\n",
        "    logging.info(f\"Loaded pre-trained model: {transfer_generator_path}\")\n",
        "    print(f\"Loaded pre-trained model: {transfer_generator_path}\")\n",
        "generator = generator.to(t_device)\n",
        "_ = generator.train()"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjCshwaeAMXL"
      },
      "source": [
        "# Freeze all layer weights except the last few, needs testing\n",
        "for param in generator.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "for param in generator.last_conv.body.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in generator.tail.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# for param in generator.conv02.parameters():\n",
        "#     param.requires_grad = True\n",
        "\n",
        "# for param in generator.body[15].parameters():\n",
        "#     param.requires_grad = True"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzXDdqMXnWlZ"
      },
      "source": [
        "def train(init_lr=1e-4, pre_train_epoch=100):\n",
        "    L2_MSE_loss = nn.MSELoss()\n",
        "    g_optim = optim.Adam(generator.parameters(), lr=init_lr)\n",
        "    g_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(g_optim, mode=\"max\", factor=0.1, patience=10, cooldown=1, verbose=True)\n",
        "\n",
        "    checkpoint_modulo = (pre_train_epoch // 3) or pre_train_epoch\n",
        "    for pre_epoch in range(1, pre_train_epoch + 1):\n",
        "        logging.info(f\"Pre-train Epoch [{pre_epoch}]: running.\")\n",
        "        for batch_i, lr_gt_datum in enumerate(loader):\n",
        "            img_lr, img_gt = lr_gt_datum['img_lr'].to(t_device), lr_gt_datum['img_gt'].to(t_device)\n",
        "            img_hr_prediction, _ = generator(img_lr)\n",
        "            loss = L2_MSE_loss(img_hr_prediction, img_gt)\n",
        "            g_optim.zero_grad()\n",
        "            loss.backward()\n",
        "            g_optim.step()\n",
        "\n",
        "        # Log epoch statistics.\n",
        "        logging.info(f\"Pre-train Epoch [{pre_epoch}]: loss={loss.item()}\")\n",
        "        print(f\"Pre-train Epoch [{pre_epoch}]: training loss={loss.item()}\")\n",
        "        # _ = test(generator=generator, mode=\"train\", write_img=False)\n",
        "        val_psnr = test(generator=generator, mode=\"val\", write_img=False)\n",
        "\n",
        "        print(f\"Pre-train Epoch [{pre_epoch}]: validation PSNR={val_psnr}\")\n",
        "        g_scheduler.step(val_psnr)\n",
        "\n",
        "        if pre_epoch % checkpoint_modulo == 0:\n",
        "            checkpoint_filepath = (checkpoint_dir / f'pre_trained_model_{pre_epoch}.pt').absolute()\n",
        "            torch.save(generator.state_dict(),  checkpoint_filepath)\n",
        "            logging.info(f\"Pre-train Epoch [{pre_epoch}]: saved model checkpoint: {checkpoint_filepath}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s20UlfpEATgf"
      },
      "source": [
        "generator_path_out = arg_util.path_abs(\"train_out/SRGAN_g_last_conv.pt\")\n",
        "generator_path_out.parent.mkdir(parents=True, exist_ok=True)\n",
        "torch.save(generator.state_dict(), generator_path_out)"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YR5c84z21phM",
        "outputId": "359bc517-934d-40b2-968f-90bd5fd3be6e"
      },
      "source": [
        "%%timeit\n",
        "# Pre-train using L2 loss\n",
        "pre_train_epoch = 100\n",
        "checkpoint_modulo = (pre_train_epoch // 3) or pre_train_epoch\n",
        "for pre_epoch in range(1, pre_train_epoch + 1):\n",
        "    logging.info(f\"Pre-train Epoch [{pre_epoch}]: running.\")\n",
        "    for batch_i, lr_gt_datum in enumerate(loader):\n",
        "        img_lr, img_gt = lr_gt_datum['img_lr'].to(t_device), lr_gt_datum['img_gt'].to(t_device)\n",
        "        img_hr_prediction, _ = generator(img_lr)\n",
        "        loss = L2_MSE_loss(img_hr_prediction, img_gt)\n",
        "        g_optim.zero_grad()\n",
        "        loss.backward()\n",
        "        g_optim.step()\n",
        "\n",
        "    # Log epoch statistics.\n",
        "    logging.info(f\"Pre-train Epoch [{pre_epoch}]: loss={loss.item()}\")\n",
        "    print(f\"Pre-train Epoch [{pre_epoch}]: training loss={loss.item()}\")\n",
        "    # _ = test(generator=generator, mode=\"train\", write_img=False)\n",
        "    val_psnr = test(generator=generator, mode=\"val\", write_img=False)\n",
        "\n",
        "    print(f\"Pre-train Epoch [{pre_epoch}]: validation PSNR={val_psnr}\")\n",
        "    g_scheduler.step(val_psnr)\n",
        "\n",
        "    if pre_epoch % checkpoint_modulo == 0:\n",
        "        checkpoint_filepath = (checkpoint_dir / f'pre_trained_model_{pre_epoch}.pt').absolute()\n",
        "        torch.save(generator.state_dict(),  checkpoint_filepath)\n",
        "        logging.info(f\"Pre-train Epoch [{pre_epoch}]: saved model checkpoint: {checkpoint_filepath}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pre-train Epoch [1]: running.\n",
            "Pre-train Epoch [1]: loss=0.0905727669596672\n",
            "Average PSNR: 20.48694627317539\n",
            "Average PSNR: 20.583544995220155\n",
            "Pre-train Epoch [2]: running.\n",
            "Pre-train Epoch [2]: loss=0.06489412486553192\n",
            "Average PSNR: 20.624586816973398\n",
            "Average PSNR: 20.723522937269646\n",
            "Pre-train Epoch [3]: running.\n",
            "Pre-train Epoch [3]: loss=0.06203813850879669\n",
            "Average PSNR: 20.74324555161233\n",
            "Average PSNR: 20.842975283628395\n",
            "Pre-train Epoch [4]: running.\n",
            "Pre-train Epoch [4]: loss=0.06971778720617294\n",
            "Average PSNR: 20.885333229521894\n",
            "Average PSNR: 20.986590571456574\n",
            "Pre-train Epoch [5]: running.\n",
            "Pre-train Epoch [5]: loss=0.05519309267401695\n",
            "Average PSNR: 20.96703452886423\n",
            "Average PSNR: 21.069493667145796\n",
            "Pre-train Epoch [6]: running.\n",
            "Pre-train Epoch [6]: loss=0.05596834048628807\n",
            "Average PSNR: 21.052831640707986\n",
            "Average PSNR: 21.156880805168218\n",
            "Pre-train Epoch [7]: running.\n",
            "Pre-train Epoch [7]: loss=0.06602142006158829\n",
            "Average PSNR: 21.144252978052357\n",
            "Average PSNR: 21.24914421337722\n",
            "Pre-train Epoch [8]: running.\n",
            "Pre-train Epoch [8]: loss=0.05144236236810684\n",
            "Average PSNR: 21.270447726091678\n",
            "Average PSNR: 21.375612756950876\n",
            "Pre-train Epoch [9]: running.\n",
            "Pre-train Epoch [9]: loss=0.05422062426805496\n",
            "Average PSNR: 21.31257875180058\n",
            "Average PSNR: 21.419575465968745\n",
            "Pre-train Epoch [10]: running.\n",
            "Pre-train Epoch [10]: loss=0.047055017203092575\n",
            "Average PSNR: 21.359772388079787\n",
            "Average PSNR: 21.46792019061499\n",
            "Pre-train Epoch [11]: running.\n",
            "Pre-train Epoch [11]: loss=0.051061250269412994\n",
            "Average PSNR: 21.43546588290071\n",
            "Average PSNR: 21.544475563025088\n",
            "Pre-train Epoch [12]: running.\n",
            "Pre-train Epoch [12]: loss=0.06018806993961334\n",
            "Average PSNR: 21.48475480615094\n",
            "Average PSNR: 21.59462360843717\n",
            "Pre-train Epoch [13]: running.\n",
            "Pre-train Epoch [13]: loss=0.0527937151491642\n",
            "Average PSNR: 21.513324548852022\n",
            "Average PSNR: 21.62397098386394\n",
            "Pre-train Epoch [14]: running.\n",
            "Pre-train Epoch [14]: loss=0.04505953565239906\n",
            "Average PSNR: 21.523964870550934\n",
            "Average PSNR: 21.63457011617785\n",
            "Pre-train Epoch [15]: running.\n",
            "Pre-train Epoch [15]: loss=0.04910248890519142\n",
            "Average PSNR: 21.558141160813722\n",
            "Average PSNR: 21.669329407536097\n",
            "Pre-train Epoch [16]: running.\n",
            "Pre-train Epoch [16]: loss=0.057481542229652405\n",
            "Average PSNR: 21.53461718446759\n",
            "Average PSNR: 21.646518705722727\n",
            "Pre-train Epoch [17]: running.\n",
            "Pre-train Epoch [17]: loss=0.05417347699403763\n",
            "Average PSNR: 21.521782775921675\n",
            "Average PSNR: 21.634220502246688\n",
            "Pre-train Epoch [18]: running.\n",
            "Pre-train Epoch [18]: loss=0.05832626298069954\n",
            "Average PSNR: 21.581484092882825\n",
            "Average PSNR: 21.69444577469785\n",
            "Pre-train Epoch [19]: running.\n",
            "Pre-train Epoch [19]: loss=0.05108126252889633\n",
            "Average PSNR: 21.590259176536996\n",
            "Average PSNR: 21.70388552923022\n",
            "Pre-train Epoch [20]: running.\n",
            "Pre-train Epoch [20]: loss=0.051457010209560394\n",
            "Average PSNR: 21.60122280032617\n",
            "Average PSNR: 21.71527716863727\n",
            "Pre-train Epoch [21]: running.\n",
            "Pre-train Epoch [21]: loss=0.049211278557777405\n",
            "Average PSNR: 21.664142773349145\n",
            "Average PSNR: 21.778782924126777\n",
            "Pre-train Epoch [22]: running.\n",
            "Pre-train Epoch [22]: loss=0.037516918033361435\n",
            "Average PSNR: 21.712762297978177\n",
            "Average PSNR: 21.827594135406567\n",
            "Pre-train Epoch [23]: running.\n",
            "Pre-train Epoch [23]: loss=0.05167857185006142\n",
            "Average PSNR: 21.752857963037812\n",
            "Average PSNR: 21.867724189832714\n",
            "Pre-train Epoch [24]: running.\n",
            "Pre-train Epoch [24]: loss=0.04569755867123604\n",
            "Average PSNR: 21.7099727844328\n",
            "Average PSNR: 21.82523965494398\n",
            "Pre-train Epoch [25]: running.\n",
            "Pre-train Epoch [25]: loss=0.055948011577129364\n",
            "Average PSNR: 21.700028319768794\n",
            "Average PSNR: 21.81605794642024\n",
            "Pre-train Epoch [26]: running.\n",
            "Pre-train Epoch [26]: loss=0.04374731704592705\n",
            "Average PSNR: 21.687384427783\n",
            "Average PSNR: 21.803487459468684\n",
            "Pre-train Epoch [27]: running.\n",
            "Pre-train Epoch [27]: loss=0.051678985357284546\n",
            "Average PSNR: 21.692346042137036\n",
            "Average PSNR: 21.80817564573741\n",
            "Pre-train Epoch [28]: running.\n",
            "Pre-train Epoch [28]: loss=0.04160059243440628\n",
            "Average PSNR: 21.739568099494882\n",
            "Average PSNR: 21.854538376889426\n",
            "Pre-train Epoch [29]: running.\n",
            "Pre-train Epoch [29]: loss=0.04438053444027901\n",
            "Average PSNR: 21.73061840842238\n",
            "Average PSNR: 21.845399420425213\n",
            "Pre-train Epoch [30]: running.\n",
            "Pre-train Epoch [30]: loss=0.052243586629629135\n",
            "Average PSNR: 21.693036925301605\n",
            "Average PSNR: 21.808275081021577\n",
            "Pre-train Epoch [31]: running.\n",
            "Pre-train Epoch [31]: loss=0.04930852726101875\n",
            "Average PSNR: 21.7512550157787\n",
            "Average PSNR: 21.866505247506925\n",
            "Pre-train Epoch [32]: running.\n",
            "Pre-train Epoch [32]: loss=0.04676232114434242\n",
            "Average PSNR: 21.77233855933253\n",
            "Average PSNR: 21.887361314904325\n",
            "Pre-train Epoch [33]: running.\n",
            "Pre-train Epoch [33]: loss=0.042084936052560806\n",
            "Average PSNR: 21.819317222202706\n",
            "Average PSNR: 21.93489282968376\n",
            "Pre-train Epoch [34]: running.\n",
            "Pre-train Epoch [34]: loss=0.06454120576381683\n",
            "Average PSNR: 21.80574259560803\n",
            "Average PSNR: 21.922395678877745\n",
            "Pre-train Epoch [35]: running.\n",
            "Pre-train Epoch [35]: loss=0.04961315914988518\n",
            "Average PSNR: 21.800212946157696\n",
            "Average PSNR: 21.916385268692512\n",
            "Pre-train Epoch [36]: running.\n",
            "Pre-train Epoch [36]: loss=0.05194031819701195\n",
            "Average PSNR: 21.7289701888414\n",
            "Average PSNR: 21.84414352023656\n",
            "Pre-train Epoch [37]: running.\n",
            "Pre-train Epoch [37]: loss=0.04865461587905884\n",
            "Average PSNR: 21.798962021974006\n",
            "Average PSNR: 21.915295888904666\n",
            "Pre-train Epoch [38]: running.\n",
            "Pre-train Epoch [38]: loss=0.0497269481420517\n",
            "Average PSNR: 21.793281620038584\n",
            "Average PSNR: 21.90923874301942\n",
            "Pre-train Epoch [39]: running.\n",
            "Pre-train Epoch [39]: loss=0.04730917513370514\n",
            "Average PSNR: 21.752255596171704\n",
            "Average PSNR: 21.868926557093218\n",
            "Pre-train Epoch [40]: running.\n",
            "Pre-train Epoch [40]: loss=0.03811899200081825\n",
            "Average PSNR: 21.771091460645934\n",
            "Average PSNR: 21.88795755748282\n",
            "Pre-train Epoch [41]: running.\n",
            "Pre-train Epoch [41]: loss=0.06016058102250099\n",
            "Average PSNR: 21.787284442699523\n",
            "Average PSNR: 21.902944871481996\n",
            "Pre-train Epoch [42]: running.\n",
            "Pre-train Epoch [42]: loss=0.05621114373207092\n",
            "Average PSNR: 21.792220403280705\n",
            "Average PSNR: 21.90878506703493\n",
            "Pre-train Epoch [43]: running.\n",
            "Pre-train Epoch [43]: loss=0.038702066987752914\n",
            "Average PSNR: 21.872329398041725\n",
            "Average PSNR: 21.988522264962636\n",
            "Pre-train Epoch [44]: running.\n",
            "Pre-train Epoch [44]: loss=0.0530514195561409\n",
            "Average PSNR: 21.877945783767828\n",
            "Average PSNR: 21.99404573655271\n",
            "Pre-train Epoch [45]: running.\n",
            "Pre-train Epoch [45]: loss=0.037816233932971954\n",
            "Average PSNR: 21.780249228941745\n",
            "Average PSNR: 21.89644505628645\n",
            "Pre-train Epoch [46]: running.\n",
            "Pre-train Epoch [46]: loss=0.04589393734931946\n",
            "Average PSNR: 21.70984409036133\n",
            "Average PSNR: 21.82645549582432\n",
            "Pre-train Epoch [47]: running.\n",
            "Pre-train Epoch [47]: loss=0.05207004025578499\n",
            "Average PSNR: 21.663861462359343\n",
            "Average PSNR: 21.78058566935644\n",
            "Pre-train Epoch [48]: running.\n",
            "Pre-train Epoch [48]: loss=0.053791675716638565\n",
            "Average PSNR: 21.743056541049935\n",
            "Average PSNR: 21.858671179858074\n",
            "Pre-train Epoch [49]: running.\n",
            "Pre-train Epoch [49]: loss=0.04923190176486969\n",
            "Average PSNR: 21.73663368387783\n",
            "Average PSNR: 21.85270560892236\n",
            "Pre-train Epoch [50]: running.\n",
            "Pre-train Epoch [50]: loss=0.056159086525440216\n",
            "Average PSNR: 21.801257849611932\n",
            "Average PSNR: 21.917461341826783\n",
            "Pre-train Epoch [51]: running.\n",
            "Pre-train Epoch [51]: loss=0.042234551161527634\n",
            "Average PSNR: 21.84488422708979\n",
            "Average PSNR: 21.961044684766247\n",
            "Pre-train Epoch [52]: running.\n",
            "Pre-train Epoch [52]: loss=0.045680586248636246\n",
            "Average PSNR: 21.74945743628823\n",
            "Average PSNR: 21.86546426815296\n",
            "Pre-train Epoch [53]: running.\n",
            "Pre-train Epoch [53]: loss=0.04911016300320625\n",
            "Average PSNR: 21.666028115239737\n",
            "Average PSNR: 21.782326732135747\n",
            "Pre-train Epoch [54]: running.\n",
            "Pre-train Epoch [54]: loss=0.04984285682439804\n",
            "Average PSNR: 21.739658271038742\n",
            "Average PSNR: 21.85509496621518\n",
            "Pre-train Epoch [55]: running.\n",
            "Pre-train Epoch [55]: loss=0.047096967697143555\n",
            "Average PSNR: 21.78500103595345\n",
            "Average PSNR: 21.900618647571378\n",
            "Pre-train Epoch [56]: running.\n",
            "Pre-train Epoch [56]: loss=0.048327792435884476\n",
            "Average PSNR: 21.788279981559082\n",
            "Average PSNR: 21.90406145067156\n",
            "Pre-train Epoch [57]: running.\n",
            "Pre-train Epoch [57]: loss=0.05600592866539955\n",
            "Average PSNR: 21.790189460910785\n",
            "Average PSNR: 21.90593859379675\n",
            "Pre-train Epoch [58]: running.\n",
            "Pre-train Epoch [58]: loss=0.04040682315826416\n",
            "Average PSNR: 21.79840959265947\n",
            "Average PSNR: 21.913927461156106\n",
            "Pre-train Epoch [59]: running.\n",
            "Pre-train Epoch [59]: loss=0.04553438350558281\n",
            "Average PSNR: 21.806462725952\n",
            "Average PSNR: 21.922093363617446\n",
            "Pre-train Epoch [60]: running.\n",
            "Pre-train Epoch [60]: loss=0.05341833457350731\n",
            "Average PSNR: 21.803566890573588\n",
            "Average PSNR: 21.91914076777412\n",
            "Pre-train Epoch [61]: running.\n",
            "Pre-train Epoch [61]: loss=0.051332227885723114\n",
            "Average PSNR: 21.804757377616458\n",
            "Average PSNR: 21.92065074604942\n",
            "Pre-train Epoch [62]: running.\n",
            "Pre-train Epoch [62]: loss=0.06246347725391388\n",
            "Average PSNR: 21.80301484060844\n",
            "Average PSNR: 21.91876811646138\n",
            "Pre-train Epoch [63]: running.\n",
            "Pre-train Epoch [63]: loss=0.052018895745277405\n",
            "Average PSNR: 21.798894957292884\n",
            "Average PSNR: 21.914740815005416\n",
            "Pre-train Epoch [64]: running.\n",
            "Pre-train Epoch [64]: loss=0.0505397729575634\n",
            "Average PSNR: 21.808029311996943\n",
            "Average PSNR: 21.923697165963834\n",
            "Pre-train Epoch [65]: running.\n",
            "Pre-train Epoch [65]: loss=0.04716091603040695\n",
            "Average PSNR: 21.810223058401554\n",
            "Average PSNR: 21.925951350238535\n",
            "Pre-train Epoch [66]: running.\n",
            "Pre-train Epoch [66]: loss=0.0436977855861187\n",
            "Average PSNR: 21.807439293414465\n",
            "Average PSNR: 21.92334373404741\n",
            "Pre-train Epoch [67]: running.\n",
            "Pre-train Epoch [67]: loss=0.061388202011585236\n",
            "Average PSNR: 21.814349910216826\n",
            "Average PSNR: 21.930082857157796\n",
            "Pre-train Epoch [68]: running.\n",
            "Pre-train Epoch [68]: loss=0.05934866890311241\n",
            "Average PSNR: 21.812944864859702\n",
            "Average PSNR: 21.9283892324375\n",
            "Pre-train Epoch [69]: running.\n",
            "Pre-train Epoch [69]: loss=0.061160340905189514\n",
            "Average PSNR: 21.81333862360067\n",
            "Average PSNR: 21.9289709019513\n",
            "Pre-train Epoch [70]: running.\n",
            "Pre-train Epoch [70]: loss=0.054840087890625\n",
            "Average PSNR: 21.81053316836452\n",
            "Average PSNR: 21.926446434011314\n",
            "Pre-train Epoch [71]: running.\n",
            "Pre-train Epoch [71]: loss=0.06781800091266632\n",
            "Average PSNR: 21.81449261469864\n",
            "Average PSNR: 21.929966697216518\n",
            "Pre-train Epoch [72]: running.\n",
            "Pre-train Epoch [72]: loss=0.055337026715278625\n",
            "Average PSNR: 21.81178684150587\n",
            "Average PSNR: 21.927444381772506\n",
            "Pre-train Epoch [73]: running.\n",
            "Pre-train Epoch [73]: loss=0.046879880130290985\n",
            "Average PSNR: 21.808259708710217\n",
            "Average PSNR: 21.924054181766135\n",
            "Pre-train Epoch [74]: running.\n",
            "Pre-train Epoch [74]: loss=0.05178089067339897\n",
            "Average PSNR: 21.805758645327877\n",
            "Average PSNR: 21.921740385775042\n",
            "Pre-train Epoch [75]: running.\n",
            "Pre-train Epoch [75]: loss=0.035826120525598526\n",
            "Average PSNR: 21.809464570678063\n",
            "Average PSNR: 21.925209238572375\n",
            "Pre-train Epoch [76]: running.\n",
            "Pre-train Epoch [76]: loss=0.05607716366648674\n",
            "Average PSNR: 21.809544153249433\n",
            "Average PSNR: 21.92511093387319\n",
            "Pre-train Epoch [77]: running.\n",
            "Pre-train Epoch [77]: loss=0.04423036053776741\n",
            "Average PSNR: 21.807976774026827\n",
            "Average PSNR: 21.923947474991127\n",
            "Pre-train Epoch [78]: running.\n",
            "Pre-train Epoch [78]: loss=0.04971212521195412\n",
            "Average PSNR: 21.807933502745655\n",
            "Average PSNR: 21.923624749945336\n",
            "Pre-train Epoch [79]: running.\n",
            "Pre-train Epoch [79]: loss=0.04940175265073776\n",
            "Average PSNR: 21.810384523795083\n",
            "Average PSNR: 21.925975125521063\n",
            "Pre-train Epoch [80]: running.\n",
            "Pre-train Epoch [80]: loss=0.050090741366147995\n",
            "Average PSNR: 21.805621977846474\n",
            "Average PSNR: 21.92138134244888\n",
            "Pre-train Epoch [81]: running.\n",
            "Pre-train Epoch [81]: loss=0.05724434554576874\n",
            "Average PSNR: 21.807859813001997\n",
            "Average PSNR: 21.9236336033875\n",
            "Pre-train Epoch [82]: running.\n",
            "Pre-train Epoch [82]: loss=0.05439707264304161\n",
            "Average PSNR: 21.808588859585306\n",
            "Average PSNR: 21.924362915358497\n",
            "Pre-train Epoch [83]: running.\n",
            "Pre-train Epoch [83]: loss=0.05531931668519974\n",
            "Average PSNR: 21.812047387984876\n",
            "Average PSNR: 21.927735269059912\n",
            "Pre-train Epoch [84]: running.\n",
            "Pre-train Epoch [84]: loss=0.05328928679227829\n",
            "Average PSNR: 21.810373787781913\n",
            "Average PSNR: 21.92611139139756\n",
            "Pre-train Epoch [85]: running.\n",
            "Pre-train Epoch [85]: loss=0.04961749538779259\n",
            "Average PSNR: 21.808183933121853\n",
            "Average PSNR: 21.924006466745166\n",
            "Pre-train Epoch [86]: running.\n",
            "Pre-train Epoch [86]: loss=0.05453522875905037\n",
            "Average PSNR: 21.810559658756116\n",
            "Average PSNR: 21.926146555257322\n",
            "Pre-train Epoch [87]: running.\n",
            "Pre-train Epoch [87]: loss=0.05043088272213936\n",
            "Average PSNR: 21.808074594176695\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2P4RRzAtQ1A"
      },
      "source": [
        "test(generator=generator, mode=\"test\", write_img=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cOBydPntQf1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k92H3Di-uRg9"
      },
      "source": [
        "# Below is Work In Progress"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "Yy-gBd561z9p",
        "outputId": "a0b84513-37b8-49e8-f108-ad4f7d02f257"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# Train using perceptual & adversarial loss\n",
        "if adversarial_train_epoch > 0:\n",
        "    logging.info(f\"Training using Adversarial loss for {adversarial_train_epoch} epochs.\")\n",
        "\n",
        "    # Set-up adversarial loss VGG network.\n",
        "    vgg_net = vgg19().to(t_device)\n",
        "    vgg_net = vgg_net.eval()\n",
        "\n",
        "    discriminator = Discriminator(patch_size=patch_size * scale)\n",
        "    discriminator = discriminator.to(t_device)\n",
        "    discriminator.train()\n",
        "\n",
        "    d_optim = optim.Adam(discriminator.parameters(), lr=1e-4)\n",
        "    scheduler = optim.lr_scheduler.StepLR(g_optim, step_size=2000, gamma=0.1)\n",
        "\n",
        "    VGG_loss = perceptual_loss(vgg_net)\n",
        "    cross_ent = nn.BCELoss()\n",
        "    tv_loss = TVLoss()\n",
        "    base_real_label = torch.ones((batch_size, 1)).to(t_device)\n",
        "    base_fake_label = torch.zeros((batch_size, 1)).to(t_device)\n",
        "\n",
        "    torch.autograd.set_detect_anomaly(True)\n",
        "    checkpoint_modulo = (adversarial_train_epoch // 10) or adversarial_train_epoch\n",
        "    for epoch in range(1, adversarial_train_epoch + 1):\n",
        "        logging.info(f\"Epoch [{epoch}]: running.\")\n",
        "\n",
        "        d_optim.step()\n",
        "        g_optim.step()\n",
        "        scheduler.step()\n",
        "        for batch_i, lr_gt_datum in enumerate(loader):\n",
        "            img_lr, img_gt = lr_gt_datum['img_lr'].to(t_device), lr_gt_datum['img_gt'].to(t_device)\n",
        "            img_hr_prediction, _ = generator(img_lr)\n",
        "\n",
        "            # Train Discriminator\n",
        "            fake_prob = discriminator(img_hr_prediction)\n",
        "            real_prob = discriminator(img_gt)\n",
        "\n",
        "            # Avoid mismatched label and probability length in case where batch is remainder of data, but not\n",
        "            # a perfect fit.\n",
        "            real_label = base_real_label\n",
        "            fake_label = base_fake_label\n",
        "            if len(base_real_label) != len(real_prob):\n",
        "                real_label = torch.ones((len(real_prob), 1)).to(t_device)\n",
        "                fake_label = torch.zeros((len(real_prob), 1)).to(t_device)\n",
        "\n",
        "            d_loss_real = cross_ent(real_prob, real_label)\n",
        "            d_loss_fake = cross_ent(fake_prob, fake_label)\n",
        "\n",
        "            d_loss = d_loss_real + d_loss_fake\n",
        "\n",
        "            # Back-propagate Discriminator\n",
        "            g_optim.zero_grad()\n",
        "            d_optim.zero_grad()\n",
        "            d_loss.backward()\n",
        "            d_optim.step()\n",
        "\n",
        "            # Train Generator\n",
        "            img_hr_prediction, _ = generator(img_lr)\n",
        "            fake_prob = discriminator(img_hr_prediction)\n",
        "\n",
        "            l2_loss = L2_MSE_loss(img_hr_prediction, img_gt)\n",
        "            percep_loss, hr_feat, sr_feat = VGG_loss((img_gt + 1.0) / 2.0, (img_hr_prediction + 1.0) / 2.0, layer=feat_layer)\n",
        "            percep_loss = vgg_rescale_coeff * percep_loss\n",
        "            adversarial_loss = adv_coeff * cross_ent(fake_prob, real_label)\n",
        "            total_variance_loss = tv_loss_coeff * tv_loss(vgg_rescale_coeff * (hr_feat - sr_feat) ** 2)\n",
        "            g_loss = percep_loss + adversarial_loss + total_variance_loss + l2_loss\n",
        "\n",
        "            # Back-propagate Generator\n",
        "            g_optim.zero_grad()\n",
        "            d_optim.zero_grad()\n",
        "            g_loss.backward()\n",
        "            g_optim.step()\n",
        "\n",
        "        # Log epoch statistics.\n",
        "        logging.info(f\"Epoch [{epoch}]: g_loss={g_loss.item()} d_loss={d_loss.item()}\")\n",
        "        if epoch % checkpoint_modulo == 0:\n",
        "            g_checkpoint_filepath = (checkpoint_dir / f'SRGAN_g_{epoch}.pt').absolute()\n",
        "            d_checkpoint_filepath = (checkpoint_dir / f'SRGAN_d_{epoch}.pt').absolute()\n",
        "            torch.save(generator.state_dict(),  g_checkpoint_filepath)\n",
        "            torch.save(discriminator.state_dict(), d_checkpoint_filepath)\n",
        "            logging.info(f\"Pre-train Epoch [{epoch}]: saved model checkpoints: {g_checkpoint_filepath}, {d_checkpoint_filepath}\")\n",
        "    if discriminator_path_out:\n",
        "        torch.save(discriminator.state_dict(), discriminator_path_out)\n",
        "torch.save(generator.state_dict(), generator_path_out)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access '/content/drive/My': No such file or directory\n",
            "ls: cannot access 'Drive/CSC420/CSC420_project-main/src/pretrained/': No such file or directory\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-a47e797f802e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpre_epoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_train_epoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Pre-train Epoch [{pre_epoch}]: running.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_gt_datum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mimg_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_gt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_gt_datum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img_lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_gt_datum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img_gt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mimg_hr_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/CSC420/CSC420_project-main/src/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mimg_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mimg_gt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgt_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0mimg_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg_lr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m127.5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mimg_gt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg_gt\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m127.5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2816\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2818\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2820\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}