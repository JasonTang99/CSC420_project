{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "finetune.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXQVrIQ3Nreq"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gGq95942DKk",
        "outputId": "d087e1f0-bf11-47b0-ab53-cf33107047e7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Change this to match your src folder location\n",
        "%cd '/content/drive/My Drive/CSC420/CSC420_project-main/src'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/CSC420/CSC420_project-main/src\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDE81ZWf1q5Q"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import pathlib\n",
        "from PIL import Image\n",
        "import random\n",
        "import multiprocessing\n",
        "import argparse\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "from arch.dataset import *\n",
        "from arch.metrics import *\n",
        "from arch.srgan_model import Generator, Discriminator\n",
        "from arch.vgg19 import vgg19\n",
        "from arch.losses import TVLoss, perceptual_loss\n",
        "from util import arg_util"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSP4boF4N0Uq"
      },
      "source": [
        "### Data and Metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEyjTTUV7f5q"
      },
      "source": [
        "# Setup Parameters\n",
        "memcache=True\n",
        "batch_size=24\n",
        "num_workers=multiprocessing.cpu_count()\n",
        "\n",
        "scale=4\n",
        "patch_size=24\n",
        "model_res_count=16\n",
        "\n",
        "# feat_layer='relu2_2'\n",
        "feat_layer='relu5_4'\n",
        "vgg_rescale_coeff=0.006\n",
        "adv_coeff=1e-3\n",
        "tv_loss_coeff=0.0\n",
        "\n",
        "t_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define Image Augmentations\n",
        "aug = transforms.Compose([\n",
        "    transforms.RandomAffine(\n",
        "        degrees=180, \n",
        "        translate=(0.2, 0.2), \n",
        "        scale=(0.7, 1.3),\n",
        "        shear=40,\n",
        "        resample=Image.BICUBIC, \n",
        "        fillcolor=255\n",
        "    ),\n",
        "    transforms.RandomPerspective(\n",
        "        distortion_scale=0.5, \n",
        "        p=0.5, \n",
        "        interpolation=Image.BICUBIC, \n",
        "        fill=255\n",
        "    ),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomGrayscale(p=0.1),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5)\n",
        "])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ihS2t8cT7VM",
        "outputId": "374c07e9-d860-4bce-d947-83fc0498deef"
      },
      "source": [
        "# Load Training Data\n",
        "gt_path = arg_util.path_abs(\"data/pokemon/hr/train/\")\n",
        "lr_path = arg_util.path_abs(\"data/pokemon/lr/train/\")\n",
        "\n",
        "lr_gt_dataset = LowResGroundTruthDataset(\n",
        "    lr_dir=lr_path, gt_dir=gt_path, memcache=memcache,\n",
        "    transform=aug\n",
        ")\n",
        "\n",
        "# Setup data loader and generator\n",
        "checkpoint_dir = arg_util.path_abs(\"train_out/\")\n",
        "checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "loader = DataLoader(lr_gt_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True)\n",
        "\n",
        "transfer_generator_path=arg_util.path_abs(\"pretrained/SRGAN.pt\")\n",
        "generator = Generator(img_feat=3, n_feats=64, kernel_size=3, num_block=model_res_count, scale=scale)\n",
        "if transfer_generator_path:\n",
        "    generator.load_state_dict(torch.load(transfer_generator_path, map_location=t_device))\n",
        "    logging.info(f\"Loaded pre-trained model: {transfer_generator_path}\")\n",
        "    print(f\"Loaded pre-trained model: {transfer_generator_path}\")\n",
        "generator = generator.to(t_device)\n",
        "generator = generator.train()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded pre-trained model: /content/drive/My Drive/CSC420/CSC420_project-main/src/pretrained/SRGAN.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IY6sDgLAzUT-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da82a752-93aa-4f57-f267-b0d2c7cf463b"
      },
      "source": [
        "# Setup Metrics Class and test initial performance\n",
        "metrics = MetricEval(lr_gt_dataset)\n",
        "metrics.load_generator(generator=generator)\n",
        "\n",
        "metrics.get_metric(mode=\"val\", metric=\"MSE\")\n",
        "metrics.get_metric(mode=\"val\", metric=\"PSNR\")\n",
        "metrics.get_metric(mode=\"val\", metric=\"VGG22\")\n",
        "metrics.get_metric(mode=\"val\", metric=\"VGG54\")\n",
        "\n",
        "# SRGAN\n",
        "# Average MSE Score: 0.0025611999444663525\n",
        "# Average PSNR Score: 27.24865229483844\n",
        "# Average VGG22 Score: 0.015313171781599522.\n",
        "# Average VGG54 Score: 0.004093066323548555"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average MSE Score: 0.0025611999444663525\n",
            "Average PSNR Score: 27.24865229483844\n",
            "Average VGG22 Score: 0.015313171781599522\n",
            "Average VGG54 Score: 0.004093066323548555\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0041, device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_ym_srvNkbF"
      },
      "source": [
        "### Training\n",
        "\n",
        "Only run this part if you'd like to train the model from the pretrained weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjCshwaeAMXL"
      },
      "source": [
        "# Freeze all layer weights except the last few\n",
        "for param in generator.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "for param in generator.last_conv.body.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in generator.tail.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# for param in generator.conv02.parameters():\n",
        "#     param.requires_grad = True\n",
        "\n",
        "# for param in generator.body[15].parameters():\n",
        "#     param.requires_grad = True"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcbS1zG31ltK"
      },
      "source": [
        "discriminator = Discriminator(patch_size = 256)\n",
        "discriminator = discriminator.to(t_device)\n",
        "discriminator = discriminator.train()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzXDdqMXnWlZ"
      },
      "source": [
        "def train(init_lr=1e-4, pre_train_epoch=100, feat_layer=\"relu5_4\"):\n",
        "    # Initialize Losses\n",
        "    vgg_net = vgg19().to(t_device)\n",
        "    vgg_net = vgg_net.eval()\n",
        "    vgg_loss = perceptual_loss(vgg_net)\n",
        "    L2_MSE_loss = nn.MSELoss()\n",
        "    cross_ent = nn.BCELoss()\n",
        "    logits_ce = nn.BCEWithLogitsLoss()\n",
        "    tv_loss = TVLoss()\n",
        "\n",
        "    real_label = torch.ones((batch_size, 1)).to(t_device)\n",
        "    fake_label = torch.zeros((batch_size, 1)).to(t_device)\n",
        "\n",
        "    global metrics, generator, discriminator\n",
        "    g_optim = optim.Adam(generator.parameters(), lr=init_lr)\n",
        "    g_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(g_optim, mode=\"min\", factor=0.5, patience=10, cooldown=0, verbose=True)\n",
        "    \n",
        "    discriminator = discriminator.train()\n",
        "    generator = generator.train()\n",
        "\n",
        "    d_optim = optim.Adam(discriminator.parameters(), lr = 5e-5)\n",
        "    d_scheduler = optim.lr_scheduler.StepLR(d_optim, step_size = 200, gamma = 0.1)\n",
        "\n",
        "    checkpoint_modulo = (pre_train_epoch // 3) or pre_train_epoch\n",
        "    for pre_epoch in range(1, pre_train_epoch + 1):\n",
        "        logging.info(f\"Pre-train Epoch [{pre_epoch}]: running.\")\n",
        "\n",
        "        # Train the Discrimator more than Generator at the start to let it catch up\n",
        "        for _ in range(max(5 - (pre_epoch//5), 1)):\n",
        "            results = []\n",
        "            for batch_i, lr_gt_datum in enumerate(loader):\n",
        "                ## Training Discriminator\n",
        "                g_optim.zero_grad()\n",
        "                d_optim.zero_grad()\n",
        "\n",
        "                img_lr, img_gt = lr_gt_datum['img_lr'].to(t_device), lr_gt_datum['img_gt'].to(t_device)\n",
        "                img_pred, _ = generator(img_lr)\n",
        "                # Resize GT to ensure its the same size as HR.\n",
        "                img_gt = img_gt[:, :, :img_pred.shape[2], :img_pred.shape[3]]\n",
        "                \n",
        "                fake_prob = discriminator(img_pred)\n",
        "                real_prob = discriminator(img_gt)\n",
        "                \n",
        "                d_loss_real = logits_ce(real_prob, real_label)\n",
        "                d_loss_fake = logits_ce(fake_prob, fake_label)\n",
        "                \n",
        "                d_loss = d_loss_real + d_loss_fake\n",
        "\n",
        "                d_loss.backward()\n",
        "                d_optim.step()\n",
        "                results.append(d_loss.item())\n",
        "            print(\"Discriminator Loss:\", sum(results)/len(results))\n",
        "            d_scheduler.step()\n",
        "\n",
        "        results = []\n",
        "        for batch_i, lr_gt_datum in enumerate(loader):\n",
        "            ## Training Generator\n",
        "            d_optim.zero_grad()\n",
        "            g_optim.zero_grad()\n",
        "\n",
        "            img_lr, img_gt = lr_gt_datum['img_lr'].to(t_device), lr_gt_datum['img_gt'].to(t_device)\n",
        "            img_pred, _ = generator(img_lr)\n",
        "\n",
        "            img_gt = ((img_gt + 1.) / 2.)\n",
        "            img_pred = ((torch.clip(img_pred, -1., 1.) + 1.) / 2.)\n",
        "            \n",
        "            # Resize GT to ensure its the same size as HR.\n",
        "            img_gt = img_gt[:, :, :img_pred.shape[2], :img_pred.shape[3]]\n",
        "\n",
        "            fake_prob = discriminator(img_pred)\n",
        "            _percep_loss, hr_feat, sr_feat = vgg_loss(img_gt, img_pred, layer=feat_layer)\n",
        "\n",
        "            g_loss = L2_MSE_loss(img_pred, img_gt) + \\\n",
        "                vgg_rescale_coeff * _percep_loss + \\\n",
        "                adv_coeff * logits_ce(fake_prob, real_label) + \\\n",
        "                tv_loss_coeff * tv_loss(vgg_rescale_coeff * (hr_feat - sr_feat)**2)\n",
        "\n",
        "            g_loss.backward()\n",
        "            g_optim.step()\n",
        "\n",
        "            results.append(g_loss.item())\n",
        "\n",
        "        # Log epoch statistics.\n",
        "        logging.info(f\"Pre-train Epoch [{pre_epoch}]: Average Train loss={sum(results)/len(results)}\")\n",
        "        print(f\"Pre-train Epoch [{pre_epoch}]: Average Train loss={sum(results)/len(results)}\")\n",
        "\n",
        "        # Evaluate Metrics on Validation Set\n",
        "        metrics.load_generator(generator=generator)\n",
        "        psnr = metrics.get_metric(mode=\"val\", metric=\"PSNR\")\n",
        "        # vgg22 = metrics.get_metric(mode=\"val\", metric=\"VGG22\")\n",
        "        vgg54 = metrics.get_metric(mode=\"val\", metric=\"VGG54\")\n",
        "        \n",
        "        generator = generator.train()\n",
        "        g_scheduler.step(vgg54)\n",
        "\n",
        "        if pre_epoch % checkpoint_modulo == 0:\n",
        "            checkpoint_filepath = (checkpoint_dir / f'pre_trained_model_{pre_epoch}.pt').absolute()\n",
        "            torch.save(generator.state_dict(),  checkpoint_filepath)\n",
        "            logging.info(f\"Pre-train Epoch [{pre_epoch}]: saved model checkpoint: {checkpoint_filepath}\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hA2xnG1pZhO7"
      },
      "source": [
        "load = True\n",
        "if load:\n",
        "    generator = Generator(img_feat=3, n_feats=64, kernel_size=3, num_block=model_res_count, scale=scale)\n",
        "    generator.load_state_dict(torch.load(\"train_out/SRGAN_pre_adv_gen.pt\", map_location=t_device))\n",
        "    generator = generator.to(t_device)\n",
        "    generator = generator.train()\n",
        "\n",
        "    discriminator.load_state_dict(torch.load(\"train_out/SRGAN_pre_adv_dis.pt\", map_location=t_device))\n",
        "    discriminator = discriminator.to(t_device)\n",
        "    discriminator = discriminator.train()\n",
        "\n",
        "train(init_lr=1e-9, pre_train_epoch=50)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iisk9St0L2AZ",
        "outputId": "360d4035-afbb-4813-8553-9c3246e6214e"
      },
      "source": [
        "# Reevaluate Metrics\n",
        "metrics.load_generator(generator=generator)\n",
        "\n",
        "metrics.get_metric(mode=\"val\", metric=\"MSE\")\n",
        "metrics.get_metric(mode=\"val\", metric=\"PSNR\")\n",
        "metrics.get_metric(mode=\"val\", metric=\"VGG22\")\n",
        "metrics.get_metric(mode=\"val\", metric=\"VGG54\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average MSE Score: 0.0023944128770381212\n",
            "Average PSNR Score: 27.449777365281214\n",
            "Average VGG22 Score: 0.012860788963735104\n",
            "Average VGG54 Score: 0.0035042911767959595\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0035, device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xt4hSKvs5TM6"
      },
      "source": [
        "# Uncomment to save current models\n",
        "\n",
        "# generator_path_out = arg_util.path_abs(\"train_out/SRGAN_pre_adv_gen.pt\")\n",
        "# discriminator_path_out = arg_util.path_abs(\"train_out/SRGAN_pre_adv_dis.pt\")\n",
        "# generator_path_out.parent.mkdir(parents=True, exist_ok=True)\n",
        "# torch.save(generator.state_dict(), generator_path_out)\n",
        "# torch.save(discriminator.state_dict(), discriminator_path_out)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5ju2SjYLZyC"
      },
      "source": [
        "### Testing and Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRyTvqVTLZRa"
      },
      "source": [
        "# Load finetuned weights\n",
        "generator = Generator(img_feat=3, n_feats=64, kernel_size=3, num_block=model_res_count, scale=scale)\n",
        "generator.load_state_dict(torch.load(\"train_out/SRGAN_pre_adv_gen.pt\", map_location=t_device))\n",
        "generator = generator.to(t_device)\n",
        "generator = generator.train()\n",
        "\n",
        "discriminator.load_state_dict(torch.load(\"train_out/SRGAN_pre_adv_dis.pt\", map_location=t_device))\n",
        "discriminator = discriminator.to(t_device)\n",
        "discriminator = discriminator.train()\n",
        "\n",
        "# Load Unfinetuned Weights to compare\n",
        "generator2 = Generator(img_feat=3, n_feats=64, kernel_size=3, num_block=model_res_count, scale=scale)\n",
        "generator2.load_state_dict(torch.load(arg_util.path_abs(\"pretrained/SRGAN.pt\"), map_location=t_device))\n",
        "generator2 = generator2.to(t_device)\n",
        "generator2 = generator2.train()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2P4RRzAtQ1A"
      },
      "source": [
        "# Generate Test Image Predictions (saved to \"results/\" folder)\n",
        "metrics.save_test_metrics(generator, generator2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwfVXMalMQgp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}